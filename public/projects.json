{
  "projects": [
    {
      "id": "project-1",
      "title": "3D Scene Reconstruction",
      "mainDescr": "Implementing NeRF on synthetic LEGO data to optimize volumetric scene models for photorealistic novel-view synthesis.",
      "description": "Building an end-to-end SfM pipeline (SIFT, RANSAC, fundamental/essential matrices, pose estimation, triangulation, PnP, bundle adjustment) to reconstruct 3D scenes from 2D images. Implementing NeRF on synthetic LEGO data to optimize volumetric scene models for photorealistic novel-view synthesis.",
      "image": "/assets/projects/reconstruction.gif",
      "images": [
        "/assets/projects/reconstruction_01.png",
        "/assets/projects/reconstruction_02.png",
        "/assets/projects/reconstruction_03.png",
        "/assets/projects/reconstruction_04.png"
      ],
      "link": "https://github.com/kshitijSharma2204/NERF-Project",
      "group": "Computer Vision",
      "skills": [
        "Python",
        "PyTorch",
        "NeRF",
        "3D Reconstruction",
        "SfM",
        "PnP",
        "RANSAC",
        "Fundamental/Essential Matrices",
        "Triangulation",
        "Bundle Adjustment"
      ],
      "favourite": true
    },
    {
      "id": "project-2",
      "title": "One-Shot Object Detection",
      "mainDescr": "Training YOLOv5n, YOLOv5s, YOLOv5m, YOLOv5l variants on a custom basketball image dataset",
      "description": "Training YOLOv5n, YOLOv5s, YOLOv5m, YOLOv5l variants on a custom basketball image dataset, comparing performance across multiple train–test splits. The goal is to achieve more than 85% average precision with YOLOv5n on multi-object, ambient-background basketball video.",
      "image": "/assets/projects/obj_detection.gif",
      "images": [
        "/assets/projects/obj_detection_01.jpg",
        "/assets/projects/obj_detection_02.jpg",
        "/assets/projects/obj_detection.gif"
      ],
      "link": "https://github.com/kshitijSharma2204/Basketball-Object-Detection",
      "group": "Computer Vision",
      "skills": [
        "Python",
        "PyTorch",
        "YOLOv5",
        "Object Detection",
        "One-Shot Learning",
        "Computer Vision",
        "Model Training",
        "Image Processing",
        "Performance Evaluation",
        "OpenCV",
        "Precision/Recall Metrics",
        "Custom Dataset Creation"
      ],
      "favourite": true
    },
    {
      "id": "project-3",
      "title": "Face Recognition/Verification Using Siamese Network",
      "mainDescr": "Develop an end-to-end face recognition system using the Siamese Network in TensorFlow",
      "description": "Develop an end-to-end face recognition system using the Siamese Network in TensorFlow and achieved at least 85% accuracy. Implementing Google’s FaceNet and a pre-trained random forest classification to compare accuracy with the results achieved with the Siamese Network.",
      "image": "/assets/projects/face_recognition_01.png",
      "images": [
        "/assets/projects/face_recognition_01.png",
        "/assets/projects/face_recognition_02.png",
        "/assets/projects/face_recognition_03.png",
        "/assets/projects/face_recognition_04.png",
        "/assets/projects/face_recognition_05.png"
      ],
      "link": "https://github.com/kshitijSharma2204/Face_Recognition_Using_Siamese_Network",
      "group": "Computer Vision",
      "skills": [
        "Python",
        "TensorFlow",
        "Siamese Network",
        "Data Augmentation",
        "Custom Dataset Creation",
        "Face Recognition",
        "Face Verification",
        "Image Processing",
        "OpenCV",
        "Deep Learning",
        "Computer Vision"
      ],
      "favourite": true
    },
    {
      "id": "project-4",
      "title": "Hybrid A*",
      "mainDescr": "Lightweight ROS 2 Hybrid A* planner for smooth, non-holonomic, collision-free paths—C++ core + Python visualization.",
      "description": "In ROS 2 Humble, this package delivers a complete Hybrid A* planning pipeline: it generates occupancy maps and goal positions, computes smooth, collision-free non-holonomic trajectories using heuristic-guided motion primitives and path smoothing, and provides real-time visualization and animation of the planned path.",
      "image": "/assets/projects/hybrid-a-star-main.gif",
      "images": [
        "/assets/projects/hybrid-a-star-main.gif"
      ],
      "link": "https://github.com/kshitijSharma2204/hybrid_astar",
      "group": "Planning and Control",
      "skills": [
        "C++",
        "ROS 2",
        "Hybrid A*",
        "Path Planning",
        "Occupancy Grids",
        "Heuristic Search",
        "Motion Primitives",
        "Reeds–Shepp Smoothing",
        "Real-Time Visualization",
        "Matplotlib Animation"
      ],
      "favourite": true
    },
    {
      "id": "project-5",
      "title": "Trajectory Generation in Frenet Frame",
      "mainDescr": "Sample and score lateral & longitudinal polynomial paths to produce real-time, collision-free vehicle motions—with full OpenCV visualization and video output.",
      "description": "Builds a center‐lane reference path (x, y, yaw, curvature, arc-length)\nGenerates lateral (quintic) & longitudinal (quartic/quintic) polynomial candidates over multiple horizons\nScores each by jerk, time, and deviation, then filters out collisions and kinematic violations\nConverts the best trajectory to world coordinates and renders all candidates + selected path with OpenCV (outputs trajectory.mp4)",
      "image": "/assets/projects/frenet-trajectory.gif",
      "images": [
        "/assets/projects/frenet-trajectory.gif"
      ],
      "link": "https://github.com/kshitijSharma2204/Trajectory-Generation-In-Frenet-Frame",
      "group": "Planning and Control",
      "skills": [
        "C++17",
        "Eigen",
        "OpenCV",
        "Polynomial Trajectory Generation",
        "Path Planning Algorithms",
        "Collision Detection",
        "Kinematic Modeling",
        "Numerical Optimization",
        "CMake",
        "Git",
        "Performance Tuning"
      ],
      "favourite": true
    },
    {
      "id": "project-6",
      "title": "EKF Localization",
      "mainDescr": "Simulates and filters a 4D unicycle trajectory with an Extended Kalman Filter—including dynamic scaling, shrinking covariance ellipse visualization, and optional MP4 output using OpenCV.",
      "description": "Initializes the EKF with state, covariance and noise matrices\nSimulates a three-phase reference path (sinusoid, straight down, semicircle)\nGenerates noisy odometry and position measurements\nRuns real-time EKF predict & update steps\nDynamically scales and centers all trajectories on the OpenCV canvas\nDraws a red covariance ellipse that shrinks as uncertainty decreases\nRenders color-coded ground truth, odometry, observations and EKF estimate\nOptionally records the animation to (ekf_demo.mp4)",
      "image": "/assets/projects/ekf_demo.gif",
      "images": [
        "/assets/projects/ekf_demo.gif"
      ],
      "link": "https://github.com/kshitijSharma2204/EKF-Localization",
      "group": "Planning and Control",
      "skills": [
        "C++",
        "Eigen",
        "OpenCV",
        "Extended Kalman Filter",
        "Sensor Fusion",
        "State Estimation",
        "Linear Algebra",
        "Probabilistic Modeling",
        "Simulation",
        "Data Visualization",
        "Random Number Generation",
        "Video Processing"
      ],
      "favourite": true
    },
    {
      "id": "project-7",
      "title": "Atari Breakout DQN Agent",
      "mainDescr": "Trains a Deep Q-Network (DQN) to master Atari Breakout using Stable-Baselines3 with frame stacking and custom preprocessing.",
      "description": "Implements a custom Breakout-v5 Gym environment with grayscale conversion, frame skipping, and 4-frame stacking\nTrains a Stable-Baselines3 DQN agent for 20 million timesteps on GPU, tuning hyperparameters for optimal performance\nIntegrates an EvalCallback to track and save the best model checkpoints during training\nUses Gym’s RecordVideo wrapper to capture high-resolution gameplay for analysis\nDemonstrates the agent’s learning curve and final policy performance in recorded video outputs",
      "image": "/assets/projects/rl-video-episode-7.gif",
      "images": [
        "/assets/projects/rl-video-episode-7.gif"
      ],
      "link": "https://github.com/kshitijSharma2204/BreakOut-Atari-RL",
      "group": "Reinforcement Learning",
      "skills": [
        "Python",
        "OpenAI Gym",
        "Stable-Baselines3",
        "Deep Q-Network (DQN)",
        "AtariPreprocessing",
        "Frame Stacking",
        "CUDA",
        "Git & GitHub",
        "Bash Scripting"
      ],
      "favourite": true
    },
    {
      "id": "project-7",
      "title": "Sliding Mode Control for Quadrotor",
      "mainDescr": "Implements a Sliding Mode Controller on the Crazyflie 2.0 for robust 3D trajectory tracking using polynomial trajectories in a Gazebo simulation.",
      "description": "Designed a robust Sliding Mode Controller (SMC) for a Crazyflie 2.0 quadrotor UAV to follow 3D polynomial trajectories in a Gazebo simulation environment. The controller handles nonlinear dynamics and external disturbances effectively. The simulation publishes rotor speeds in real-time to Gazebo and logs flight data for visualization. Includes 5th-order polynomial trajectory generation, control allocation matrix, and dynamic SMC tuning parameters. A visualization script generates 3D plots of the actual trajectory.",
      "image": "/assets/projects/SlidingMode_quad.gif",
      "images": [
        "/assets/projects/SlidingMode_quad.gif"
      ],
      "link": "https://github.com/kshitijSharma2204/Sliding_Mode_Controller_for_UAV",
      "group": "Planning and Control",
      "skills": [
        "Python",
        "ROS Noetic",
        "Gazebo",
        "Crazyflie 2.0",
        "Sliding Mode Control",
        "Nonlinear Dynamics",
        "Control Systems",
        "Polynomial Trajectories",
        "Robot Simulation",
        "3D Visualization",
        "Matplotlib"
      ],
      "favourite": true
    },
    {
      "id": "project-7",
      "title": "Travelling Salesman Problem",
      "mainDescr": "Developed Python-based Algorithms to solve the Travelling Salesman Problem with interactive visualization and MP4 animation output.",
      "description": "Implemented a customizable Genetic Algorithm in Python to approximate optimal tours for the TSP. Features include greedy-seeded initial population, elitism and roulette‐wheel selection, ordered crossover, and distance-based mutation. Integrated real-time Matplotlib plots of route improvement and generated an MP4 animation of the GA’s convergence over generations.",
      "image": "/assets/projects/tsp.gif",
      "images": [
        "/assets/projects/tsp.gif"
      ],
      "link": "https://github.com/kshitijSharma2204/Travelling_Salesman_Problem_DSA",
      "group": "Algorithm Development",
      "skills": [
        "Python",
        "Matplotlib",
        "NumPy",
        "Pandas",
        "Object-Oriented Programming",
        "Data Visualization",
        "Algorithm Design",
        "Animation"
      ],
      "favourite": true
    },
    {
      "id": "project-8",
      "title": "Joint Space Control of SCARA arm",
      "mainDescr": "Developed a ROS-based PID control system with inverse kinematics for precise joint-space manipulation of a SCARA robot arm.",
      "description": "This project implements a joint-space control scheme for a SCARA robotic manipulator using ROS. It features an inverse kinematics solver to calculate joint parameters from target positions, a PID controller to precisely maneuver the robot arm's joints, and real-time visualization and trajectory plotting. The solution is structured into ROS packages including service servers, subscribers, and publishers for seamless robotic control.",
      "image": "/assets/projects/JointSpace_traj.gif",
      "images": [
        "/assets/projects/JointSpace_traj.gif"
      ],
      "link": "https://github.com/kshitijSharma2204/Joint_Space_Control_of_SCARA_Robot_Manipulator",
      "group": "Planning and Control",
      "skills": [
        "ROS",
        "Python",
        "PID Control",
        "Inverse Kinematics"
      ],
      "favourite": true
    }
  ]
}
